{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook I try to make prediction on the Gold price using machine learning methods. The workflow of this prediction and its steps are as the following:\n",
    "### Data Preparation\n",
    "After importing the data which is the Gold price from August of 2000 to October of 2022, we need to prepare the dataset by feature engineering and exploratory data analysis. Briefly, we add lag columns and their statistics. At the end of this part, I defined a function that do all we need we some arguments.\n",
    "\n",
    "### Machine Learning Model\n",
    "In this section, I chose LGBMRegressor as the ML model for prediciting the price and tuned it with verstack.\n",
    "\n",
    "### Trading Strategy\n",
    "Finally, I created a trading strategy using the price we predicted in the last section which return the profit we make, if we trust to the model.\n",
    "\n",
    "### Result\n",
    "We know that financial markets are very \"Complex\" and need very high level mathematics like Stochastic Analysis for making any prediction or analysis.\n",
    "Nevertheless, I did this type of prediction just for making sense of the market and I plan to use more mathematical approaches for this objective in the soon future and will publish it here.\n",
    "\n",
    "### Profit\n",
    "By the trading strategy mentioned above, we observe more than 20% profit in 3 month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-04T12:06:41.139335Z",
     "iopub.status.busy": "2022-11-04T12:06:41.138915Z",
     "iopub.status.idle": "2022-11-04T12:08:59.096904Z",
     "shell.execute_reply": "2022-11-04T12:08:59.093618Z",
     "shell.execute_reply.started": "2022-11-04T12:06:41.139301Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install verstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-04T12:11:29.813522Z",
     "iopub.status.busy": "2022-11-04T12:11:29.811358Z",
     "iopub.status.idle": "2022-11-04T12:11:45.516919Z",
     "shell.execute_reply": "2022-11-04T12:11:45.515528Z",
     "shell.execute_reply.started": "2022-11-04T12:11:29.813443Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/OpenHydrology/lmoments3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:11.384006Z",
     "iopub.status.busy": "2022-11-04T12:12:11.383505Z",
     "iopub.status.idle": "2022-11-04T12:12:18.420786Z",
     "shell.execute_reply": "2022-11-04T12:12:18.419622Z",
     "shell.execute_reply.started": "2022-11-04T12:12:11.383963Z"
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from scipy import stats\n",
    "import lmoments3 as lm\n",
    "from numpy import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from verstack import LGBMTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:21.921305Z",
     "iopub.status.busy": "2022-11-04T12:12:21.920412Z",
     "iopub.status.idle": "2022-11-04T12:12:22.412525Z",
     "shell.execute_reply": "2022-11-04T12:12:22.411387Z",
     "shell.execute_reply.started": "2022-11-04T12:12:21.921262Z"
    }
   },
   "outputs": [],
   "source": [
    "Gold = pd.read_csv(r'../input/gold-price-2000-2022/gold price - 2000 edited.csv',\n",
    "                  header=0, index_col=0, parse_dates=True,squeeze=True)\n",
    "Gold = Gold[Gold.Open !=0]\n",
    "Gold = Gold[Gold.High !=0]\n",
    "Gold = Gold[Gold.Low !=0]\n",
    "Gold = Gold[Gold.Close !=0]\n",
    "Gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## Select best Lags\n",
    "\n",
    "* The first function create the lags we specify and add them to the dataset.\n",
    "* If we want to use lag for our time series forcasting, we should know which lag is better to add to our dataset.\n",
    "* The second function use Mutual Information score to detect most relevant and important lags to the column we wish to predict or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:31.778169Z",
     "iopub.status.busy": "2022-11-04T12:12:31.777755Z",
     "iopub.status.idle": "2022-11-04T12:12:31.785498Z",
     "shell.execute_reply": "2022-11-04T12:12:31.784244Z",
     "shell.execute_reply.started": "2022-11-04T12:12:31.778138Z"
    }
   },
   "outputs": [],
   "source": [
    "# add lags we set in \"lag_list\" and place them in order to the dataset.\n",
    "\n",
    "def Add_Lag(data,col,lag_list):\n",
    "    \n",
    "    position = data.columns.tolist().index(col)\n",
    "    \n",
    "    for lag in lag_list:\n",
    "    \n",
    "        col_val = data[col].shift(lag)\n",
    "\n",
    "        col_name = col+'_lag:'+'{length}'.format(length=lag)\n",
    "\n",
    "        data.insert(loc=position, column=col_name, value=col_val)\n",
    "        \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:34.050436Z",
     "iopub.status.busy": "2022-11-04T12:12:34.049996Z",
     "iopub.status.idle": "2022-11-04T12:12:34.066461Z",
     "shell.execute_reply": "2022-11-04T12:12:34.064963Z",
     "shell.execute_reply.started": "2022-11-04T12:12:34.050402Z"
    }
   },
   "outputs": [],
   "source": [
    "def mutual_information_lag(Data,col,n_lag,k_best):\n",
    "    \n",
    "    #create a dataset by selecting just one column from Gold dataset; a dataset with just one column of {Open,Close,High,Low,Volume} and time as index\n",
    "    data = pd.DataFrame(Data[col])\n",
    "    \n",
    "    #create the dataset that its columns are lags with different shifts\n",
    "    mic_df = Add_Lag(data,col,[i+1 for i in range(n_lag)])\n",
    "    \n",
    "    mic_ordered = {}\n",
    "    \n",
    "    #calculating the mutual information score between lag columns and target column; one of {Open,Close,High,Low,Volume} which selected above\n",
    "    for i in range(1,n_lag+1):\n",
    "        \n",
    "        i_lag = mic_df[mic_df.columns[mic_df.shape[1]-i-1]][i:]\n",
    "        i_lag_name = mic_df.columns[mic_df.shape[1]-i-1]\n",
    "        score = mutual_info_regression(np.array(i_lag).reshape(-1, 1), mic_df[col][i:])\n",
    "        mic_ordered[i_lag_name] = score[0]\n",
    "    \n",
    "    #descend sort the lag list by their mutual information score\n",
    "    sorted_mic = {k: v for k, v in sorted(mic_ordered.items(),reverse=True, key=lambda item: item[1])}\n",
    "    \n",
    "    #select the k first lags that have most mutual information scor\n",
    "    selected_lags = list(sorted_mic.keys())[:k_best]\n",
    "    \n",
    "    #create a list of best k lags obtained above\n",
    "    select_lag_num = []\n",
    "    for i in selected_lags:\n",
    "        \n",
    "        pos = i.find(':')\n",
    "        select_lag_num.append(int(i[pos+1:]))\n",
    "        \n",
    "    select_lag_num_sort = sorted(select_lag_num)\n",
    "    \n",
    "    #draw a plot that visualize all lags (not just best k lags) and their mutul information score with the target\n",
    "    plt.plot([i+1 for i in range(n_lag)], sorted_mic.values(),'--bo', label = \"mutual information score\",linestyle = 'dashed')\n",
    "    plt.xticks(rotation = 90)njh\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return select_lag_num_sort,sorted_mic,selected_lags,sorted_mic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:34.405415Z",
     "iopub.status.busy": "2022-11-04T12:12:34.404126Z",
     "iopub.status.idle": "2022-11-04T12:12:37.699982Z",
     "shell.execute_reply": "2022-11-04T12:12:37.698621Z",
     "shell.execute_reply.started": "2022-11-04T12:12:34.405362Z"
    }
   },
   "outputs": [],
   "source": [
    "#try the function on the \"Close price\" of the Gold data, calculating 100 first lags and select 10 high mutual information score lags\n",
    "Best_Lags = mutual_information_lag(Gold,'Close',100,10)\n",
    "#as we can see in the following almost best k lags are first k lags "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Features\n",
    "* In the following some summary statistics defined for adding to the dataset.\n",
    "* For mathematical definitions of this function you can refer to the below notebook:\n",
    "* https://www.kaggle.com/code/khashayarrahimi94/lgbm-using-summary-statistics-tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:41.612879Z",
     "iopub.status.busy": "2022-11-04T12:12:41.611531Z",
     "iopub.status.idle": "2022-11-04T12:12:41.619338Z",
     "shell.execute_reply": "2022-11-04T12:12:41.618203Z",
     "shell.execute_reply.started": "2022-11-04T12:12:41.612813Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_coefficient(x):\n",
    "    #Compute Gini coefficient of array of values\n",
    "    diffsum = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        diffsum += np.sum(np.abs(xi - x[i:]))\n",
    "    return diffsum / (len(x)**2 * np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:42.642586Z",
     "iopub.status.busy": "2022-11-04T12:12:42.642146Z",
     "iopub.status.idle": "2022-11-04T12:12:42.653445Z",
     "shell.execute_reply": "2022-11-04T12:12:42.652123Z",
     "shell.execute_reply.started": "2022-11-04T12:12:42.642551Z"
    }
   },
   "outputs": [],
   "source": [
    "def Roll_Stats(data,col,Window):\n",
    "    \n",
    "    lag = 2\n",
    "    \n",
    "    \"\"\"\n",
    "    Important:\n",
    "    \n",
    "    Setting Lag=2 is because our trading strategy. By lag=2 these statistics computed from 2 days before prediction to more days back.\n",
    "    \n",
    "    \"\"\"\n",
    "    position = data.columns.tolist().index(col)\n",
    "\n",
    "    col_val = data[col].shift(lag)\n",
    "    window1 = col_val.rolling(window=Window)\n",
    "    #window2 = col_val.rolling(window=Window+5)\n",
    "    \"\"\"\n",
    "    Adding window by 3 because we need more general value for our min and max,\n",
    "    Actually if we dont add 3, the min and max repeated because they existed in the data as lags\n",
    "    \"\"\" \n",
    "    \n",
    "    means = window1.mean()\n",
    "    std = window1.var()\n",
    "    #Max  = window2.max()\n",
    "    #Min = window2.min()\n",
    "    \n",
    "    col_name_mean = col+'_mean'+'_lag:'+'{length}'.format(length=lag)+\\\n",
    "    '_win:'+'{length}'.format(length=Window)\n",
    "    col_name_std = col+'_std'+'_lag:'+'{length}'.format(length=lag)+\\\n",
    "    '_win:'+'{length}'.format(length=Window)\n",
    "    #col_name_max = col+'_max'+'_lag:'+'{length}'.format(length=lag)+\\\n",
    "    #'_win:'+'{length}'.format(length=Window)\n",
    "    #col_name_min = col+'_min'+'_lag:'+'{length}'.format(length=lag)+\\\n",
    "    #'_win:'+'{length}'.format(length=Window)\n",
    "    \n",
    "    data.insert(loc=position, column=col_name_mean, value=means)\n",
    "    data.insert(loc=position, column=col_name_std, value=std)\n",
    "    #data.insert(loc=position, column=col_name_max, value=Max)\n",
    "    #data.insert(loc=position, column=col_name_min, value=Min)\n",
    "        \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:44.122119Z",
     "iopub.status.busy": "2022-11-04T12:12:44.121714Z",
     "iopub.status.idle": "2022-11-04T12:12:44.137179Z",
     "shell.execute_reply": "2022-11-04T12:12:44.135767Z",
     "shell.execute_reply.started": "2022-11-04T12:12:44.122087Z"
    }
   },
   "outputs": [],
   "source": [
    "def L_moment(data,col,Window):\n",
    "    \n",
    "    position = data.columns.tolist().index(col)\n",
    "    \n",
    "    Len = data.shape[0]-Window\n",
    "    col_val = data[col].shift(1)\n",
    "    \n",
    "    col_name_1 = col+'_win:'+'{length}'.format(length=Window)+\\\n",
    "    '_L:'+'{moment}'.format(moment=1)\n",
    "    col_name_2 = col+'_win:'+'{length}'.format(length=Window)+\\\n",
    "    '_L:'+'{moment}'.format(moment=2)\n",
    "    col_name_3 = col+'_win:'+'{length}'.format(length=Window)+\\\n",
    "    '_L:'+'{moment}'.format(moment=3)\n",
    "    col_name_4 = col+'_win:'+'{length}'.format(length=Window)+\\\n",
    "    '_L:'+'{moment}'.format(moment=4)\n",
    "    col_name_5 = col+'_win:'+'{length}'.format(length=Window)+\\\n",
    "    '_L:'+'{moment}'.format(moment=5)\n",
    "    col_name_6 = col+'_win:'+'{length}'.format(length=Window)+'_gini'\n",
    "    \n",
    "    L1 = [np.nan]*Window\n",
    "    L2 = [np.nan]*Window\n",
    "    L3 = [np.nan]*Window\n",
    "    L4 = [np.nan]*Window\n",
    "    L5 = [np.nan]*Window\n",
    "    Gini = [np.nan]*Window\n",
    "    \n",
    "    for i in range(Len):\n",
    "        \n",
    "        lmoments = lm.lmom_ratios(col_val[i:i+Window].round(3).tolist(), nmom=5)\n",
    "        gini = gini_coefficient(col_val[i:i+Window].round(3))\n",
    "        \n",
    "        L1.append(lmoments[0])\n",
    "        L2.append(lmoments[1])\n",
    "        L3.append(lmoments[2])\n",
    "        L4.append(lmoments[3])\n",
    "        L5.append(lmoments[4])\n",
    "        Gini.append(gini)\n",
    "        \n",
    "    data.insert(loc=position, column=col_name_5, value=L5)\n",
    "    data.insert(loc=position, column=col_name_4, value=L4)\n",
    "    data.insert(loc=position, column=col_name_3, value=L3)\n",
    "    data.insert(loc=position, column=col_name_2, value=L2)\n",
    "    data.insert(loc=position, column=col_name_1, value=L1)\n",
    "    data.insert(loc=position, column=col_name_6, value=Gini)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:12:46.179573Z",
     "iopub.status.busy": "2022-11-04T12:12:46.179179Z",
     "iopub.status.idle": "2022-11-04T12:12:46.186951Z",
     "shell.execute_reply": "2022-11-04T12:12:46.185534Z",
     "shell.execute_reply.started": "2022-11-04T12:12:46.179541Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is the final function that use above functions and return the prepared dataset\n",
    "def Prepare_Data(data,col,Lag_list,Roll_window,Lmoment_window):\n",
    "    \n",
    "    if Roll_window <2:\n",
    "        print('Roll_window must be greater than 1.')\n",
    "\n",
    "    Add_Lag(data,col,Lag_list)\n",
    "    Roll_Stats(data,col,Roll_window)\n",
    "    L_moment(data,col,Lmoment_window)\n",
    "\n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T09:56:59.15566Z",
     "iopub.status.busy": "2022-11-04T09:56:59.155263Z",
     "iopub.status.idle": "2022-11-04T09:57:13.807476Z",
     "shell.execute_reply": "2022-11-04T09:57:13.806101Z",
     "shell.execute_reply.started": "2022-11-04T09:56:59.155628Z"
    }
   },
   "outputs": [],
   "source": [
    "#try the function\n",
    "data = pd.DataFrame({'High':Gold['High']}, index = Gold.index)\n",
    "data = Prepare_Data(data,'High',[2,3],2,5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:48:05.609429Z",
     "iopub.status.busy": "2022-11-04T12:48:05.608881Z",
     "iopub.status.idle": "2022-11-04T12:48:05.628956Z",
     "shell.execute_reply": "2022-11-04T12:48:05.627731Z",
     "shell.execute_reply.started": "2022-11-04T12:48:05.60938Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(Data,col,Lag_list,Roll_window,Lmoment_window):\n",
    "\n",
    "    data = pd.DataFrame({col:Data[col]}, index = Data.index)\n",
    "    \n",
    "    #prepare the target column we wish to predict\n",
    "    data = Prepare_Data(data,col,Lag_list,Roll_window,Lmoment_window)\n",
    "    \n",
    "    #these three columns with their new features add to the final dataset, whatever the target column is. \n",
    "    Open = Prepare_Data(pd.DataFrame(Gold['Open']),'Open',Lag_list,Roll_window,Lmoment_window)\n",
    "    Close = Prepare_Data(pd.DataFrame(Gold['Close']),'Close',Lag_list,Roll_window,Lmoment_window)\n",
    "    Volume = Prepare_Data(pd.DataFrame(Gold['Volume']),'Volume',Lag_list,Roll_window,Lmoment_window)\n",
    "    \n",
    "    #Due to creating a complete dataset containg all features, if the target is \"High\" we add Low features and vice versa.\n",
    "    if col == 'High':\n",
    "        df = Prepare_Data(pd.DataFrame(Gold['Low']),'Low',Lag_list,Roll_window,Lmoment_window)\n",
    "        \n",
    "    elif col == 'Low':\n",
    "        df = Prepare_Data(pd.DataFrame(Gold['High']),'High',Lag_list,Roll_window,Lmoment_window)\n",
    "        \n",
    "    #now we merge all the dataset we created above together to have a complete dataset \n",
    "    data = pd.concat([Open,Close,Volume,df,data],axis=1)\n",
    "    \n",
    "    #eliminate rows that have missing values due to using lags\n",
    "    tail = data.shape[0]-max(Roll_window,len(Lag_list))\n",
    "    data = data.tail(tail)\n",
    "    \n",
    "    #define train data\n",
    "    X = data.values[:-90,:-1]\n",
    "    Y = data.values[:-90,-1]\n",
    "\n",
    "    #use lgbmtuner for hyperparaeter tuning\n",
    "    tuner = LGBMTuner(metric = 'rmse',trials = 50) # <- the only required argument\n",
    "\n",
    "    #the tuner needs these datatype for X and Y\n",
    "    X = pd.DataFrame(X)\n",
    "    Y = pd.Series(Y)\n",
    "    \n",
    "    #fit the tuned model and make prediction on the last 90 days of the data\n",
    "    tuner.fit(X,Y)\n",
    "    x_test = data.values[-90:,:-1]\n",
    "    x_test = pd.DataFrame(x_test)\n",
    "    predict = tuner.predict(x_test)\n",
    "    \n",
    "    y_test = pd.Series(data.values[-90:,-1])\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predict)\n",
    "    rmse = sqrt(mean_squared_error(y_test, predict))\n",
    "    \n",
    "    \n",
    "    \"\"\"The best case for both diff in the following is small positive numbers\n",
    "    which means the prediction is accurate and the trading strategy is possible.\"\"\" \n",
    "    \n",
    "    diff_low = [] \n",
    "    if col=='Low':\n",
    "        \n",
    "        for i in range(len(predict)):\n",
    "            \n",
    "            diff = predict[i] - y_test[i]\n",
    "        \n",
    "            diff_low.append(diff)\n",
    "            \n",
    "        print ('Mean:',mean(diff_low),'Variance:',statistics.variance(diff_low))\n",
    "\n",
    "            \n",
    "    diff_high = [] \n",
    "    if col=='High':\n",
    "        \n",
    "        for i in range(len(predict)):\n",
    "            \n",
    "            diff =  y_test[i] - predict[i]\n",
    "        \n",
    "            diff_high.append(diff)\n",
    "        \n",
    "        print ('Mean:',mean(diff_high),'Variance:',statistics.variance(diff_high))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('MAE: %f' % mae)\n",
    "    print('RMSE: %f' % rmse)\n",
    "    print('======Summary======')\n",
    "    print('Lag_list:','===>',Lag_list)\n",
    "    print('Roll_window:','===>',Roll_window)\n",
    "    print('Lmoment_window:','===>',Lmoment_window)\n",
    "    #print('n_estimator:','===>',N_estimator)\n",
    "    #print('Learing Rate:','===>',Learning_R)\n",
    "    print('==============================')\n",
    "    print('predict:\\n',[ '%.1f' % y for y in predict ])\n",
    "    print('Actual:\\n', y_test.tolist())\n",
    "\n",
    "    return predict.tolist(),y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-04T12:48:25.647238Z",
     "iopub.status.busy": "2022-11-04T12:48:25.645988Z",
     "iopub.status.idle": "2022-11-04T12:55:11.34964Z",
     "shell.execute_reply": "2022-11-04T12:55:11.348111Z",
     "shell.execute_reply.started": "2022-11-04T12:48:25.647189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_prediction = prediction(Gold,'Low',[i for i in range(2,6)],2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T10:16:59.570907Z",
     "iopub.status.busy": "2022-11-04T10:16:59.569544Z",
     "iopub.status.idle": "2022-11-04T10:16:59.869574Z",
     "shell.execute_reply": "2022-11-04T10:16:59.866139Z",
     "shell.execute_reply.started": "2022-11-04T10:16:59.570862Z"
    }
   },
   "outputs": [],
   "source": [
    "x = data[-90:].index\n",
    "x = pd.DataFrame(Gold.index[-90:]).values\n",
    "# plot Low prediction and actual price\n",
    "plt.plot(x, low_prediction[0],'--bo', label = \"predict\",linestyle = 'dashed')\n",
    "plt.plot(x, low_prediction[1],marker='o', label = \"Actual\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-04T12:59:04.757691Z",
     "iopub.status.busy": "2022-11-04T12:59:04.757175Z",
     "iopub.status.idle": "2022-11-04T13:08:09.149397Z",
     "shell.execute_reply": "2022-11-04T13:08:09.148075Z",
     "shell.execute_reply.started": "2022-11-04T12:59:04.757654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "high_prediction = prediction(Gold,'High',[i for i in range(2,6)],2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T10:28:44.430069Z",
     "iopub.status.busy": "2022-11-04T10:28:44.429612Z",
     "iopub.status.idle": "2022-11-04T10:28:44.706402Z",
     "shell.execute_reply": "2022-11-04T10:28:44.705228Z",
     "shell.execute_reply.started": "2022-11-04T10:28:44.430034Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot High prediction and actual price\n",
    "plt.plot(x, high_prediction[0],'--bo', label = \"predict\",linestyle = 'dashed')\n",
    "plt.plot(x, high_prediction[1],marker='o', label = \"Actual\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Strategy\n",
    "\n",
    "Due to the limitation of information in our dataset, we can not trade daily based on \"Low\" and \"High\" price prediction.\n",
    "The simplest strategy is buying at the Low price in a day and sell at the High price on that day. But since we dont have more detailed data including hourly price, we can not know the order of Low and High price; Which one occured before the other in each day?\n",
    "\n",
    "Therefore, we create another strategy:\n",
    "\n",
    "Since our prediction for day(i) is done by the information from day(j) where j < i-1 (means two days before day(i)), we have predictions for the Low price of day(i-1) and High price of day(i), we can buy in the low price of day(i-1) hope for High price of day(i) for selling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:20:30.348024Z",
     "iopub.status.busy": "2022-11-04T13:20:30.347424Z",
     "iopub.status.idle": "2022-11-04T13:20:30.364409Z",
     "shell.execute_reply": "2022-11-04T13:20:30.362938Z",
     "shell.execute_reply.started": "2022-11-04T13:20:30.347974Z"
    }
   },
   "outputs": [],
   "source": [
    "def trading_strategy(money,pre_Low,pre_High,low_add,high_loss):\n",
    "    \n",
    "    \"\"\"\n",
    "    \"low_add\" and \"high_loss\" are two values we respectively add and subtract to and from low and high price predictions.\n",
    "    By this, we raise the probability of trading and derease the profit, but if you try this approach and it's alternate\n",
    "    (don't use these two values) you will convince to use them.\n",
    "    \"\"\" \n",
    "    money_model = money\n",
    "    money_optimal = money\n",
    "    \n",
    "    pre_low = pre_Low[0]\n",
    "    pre_high = pre_High[0]\n",
    "    \n",
    "    act_low = pre_Low[1]\n",
    "    act_high = pre_High[1]\n",
    "    \n",
    "    profit_model = 0\n",
    "    profit_optimal = 0\n",
    "    i = 0\n",
    "    \n",
    "    #By un-comment the following comments, you can see daily profit based on model prediction\n",
    "\n",
    "    while i < 89:\n",
    "\n",
    "            if (pre_low[i]+low_add >= act_low[i]) and (pre_low[i]+low_add < pre_high[i+1]):\n",
    "\n",
    "                gold_bought = money_model/(pre_low[i]+low_add)\n",
    "                #print('pre_low:',pre_low[i])\n",
    "                #print('gold_bought:',i,gold_bought)\n",
    "                \n",
    "                i = i + 1\n",
    "                j = i\n",
    "                while j < 89:\n",
    "\n",
    "                    if (act_high[j] >= pre_high[j]-high_loss):\n",
    "\n",
    "                        diff_model = gold_bought * (pre_high[j]-high_loss) - money_model\n",
    "                        #print('day {}: Diff'.format(j),diff_model)\n",
    "                        profit_model = profit_model + diff_model\n",
    "                        #print('day {}: Profit'.format(j),profit_model)\n",
    "                        money_model = money_model + diff_model\n",
    "                        #print('day {}: Money'.format(i),money_model)\n",
    "                        #print('=============================================')\n",
    "                        i = i + 1\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        j = j + 1\n",
    "                        i = j\n",
    "\n",
    "            else:\n",
    "                #print('last',i)\n",
    "\n",
    "                i = i + 1\n",
    "                \n",
    "    final_profit_model = 0\n",
    "    last_day_sell_pice = mean([pre_low[89], pre_high[89]])\n",
    "    \n",
    "    if last_day_sell_pice < act_high[89]:\n",
    "                \n",
    "        final_profit_model = max(profit_model,gold_bought*last_day_sell_pice)-1000\n",
    "    \n",
    "    # The below code snippet creat the \"Ideal Case\" which is when you know the exat low and high price and trade as above \n",
    "    \n",
    "    j = 0\n",
    "    while j < 89:\n",
    "\n",
    "        if act_low[j] < act_high[j+1]:\n",
    "            diff_optimal = ((money_optimal/act_low[j]) * act_high[j+1] - money_optimal)\n",
    "            #print(diff_optimal)\n",
    "            profit_optimal = profit_optimal + diff_optimal\n",
    "            #print(profit_optimal)\n",
    "            money_optimal = money_optimal + diff_optimal\n",
    "            #print(money_optimal)\n",
    "\n",
    "            j = j + 2\n",
    "            #print(j)\n",
    "            #print('*************')\n",
    "\n",
    "        else:\n",
    "            j = j + 1\n",
    "            \n",
    "    print('Optimal:')\n",
    "    print('profit:',profit_optimal,'Capital:',money_optimal)\n",
    "    print('============')\n",
    "    print('Model:')\n",
    "    print('profit:',final_profit_model,'Capital:',1000+final_profit_model)\n",
    "    \n",
    "    return final_profit_model,profit_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:16:49.011938Z",
     "iopub.status.busy": "2022-11-04T14:16:49.010823Z",
     "iopub.status.idle": "2022-11-04T14:16:49.020265Z",
     "shell.execute_reply": "2022-11-04T14:16:49.018949Z",
     "shell.execute_reply.started": "2022-11-04T14:16:49.011876Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tuning the trading_strategy\n",
    "def tune_strategy(low_prediction,high_prediction):\n",
    "    profit_dict = {}\n",
    "    for i in np.arange(0, 5, 0.1):\n",
    "\n",
    "        for j in np.arange(0, 5, 0.1):\n",
    "\n",
    "            profit = trading_strategy(1000,low_prediction,high_prediction,i,j)[0]\n",
    "            \n",
    "            profit_dict[(i,j)] = profit\n",
    "    \n",
    "    sorted_dict = {k: v for k, v in sorted(profit_dict.items(),reverse=True, key=lambda item: item[1])}\n",
    "    \n",
    "    best_parameters = list(sorted_dict.keys())[0]\n",
    "    \n",
    "    return best_parameters,sorted_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-04T14:16:54.936732Z",
     "iopub.status.busy": "2022-11-04T14:16:54.935976Z",
     "iopub.status.idle": "2022-11-04T14:16:55.337911Z",
     "shell.execute_reply": "2022-11-04T14:16:55.336476Z",
     "shell.execute_reply.started": "2022-11-04T14:16:54.936695Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_param = tune_strategy(low_prediction,high_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:17:23.028262Z",
     "iopub.status.busy": "2022-11-04T14:17:23.027761Z",
     "iopub.status.idle": "2022-11-04T14:17:23.037378Z",
     "shell.execute_reply": "2022-11-04T14:17:23.036014Z",
     "shell.execute_reply.started": "2022-11-04T14:17:23.028223Z"
    }
   },
   "outputs": [],
   "source": [
    "print('low_add:',best_param[0][0])\n",
    "print('high_loss:',best_param[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:17:44.541375Z",
     "iopub.status.busy": "2022-11-04T14:17:44.540222Z",
     "iopub.status.idle": "2022-11-04T14:17:44.55285Z",
     "shell.execute_reply": "2022-11-04T14:17:44.551382Z",
     "shell.execute_reply.started": "2022-11-04T14:17:44.541324Z"
    }
   },
   "outputs": [],
   "source": [
    "trading_strategy(1000,low_prediction,high_prediction,best_param[0][0],best_param[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:26:44.100279Z",
     "iopub.status.busy": "2022-11-04T13:26:44.09975Z",
     "iopub.status.idle": "2022-11-04T13:26:44.109937Z",
     "shell.execute_reply": "2022-11-04T13:26:44.108361Z",
     "shell.execute_reply.started": "2022-11-04T13:26:44.100238Z"
    }
   },
   "outputs": [],
   "source": [
    "trading_strategy(1000,low_prediction,high_prediction,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "**Where the maximum possible profit is <50% of the first fund which is 1000 dollor, our prediction help us to earn more than 20%.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
